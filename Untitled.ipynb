{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a310fc50-717f-4257-85c1-297129554cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dancostin/Repos/book-worm/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from llama_cpp import Llama, LogitsProcessorList\n",
    "from lmformatenforcer import CharacterLevelParser, JsonSchemaParser\n",
    "from lmformatenforcer.integrations.llamacpp import build_llamacpp_logits_processor, build_token_enforcer_tokenizer_data\n",
    "\n",
    "from src.utils.lexrank import degree_centrality_scores\n",
    "from src.utils.prompts import get_summarization_prompt, get_question_prompt\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "SENTENCE_TRANSFORMERS_HOME=\"./models/embeddings\"\n",
    "MODEL_PATH = \"models/llama-2-13b-chat.Q2_K.gguf\"\n",
    "EMBEDDING_MODEL_PATH = \"all-mpnet-base-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd77e34f-56fc-4ee8-ba9d-3bcddaa626ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_PATH,\n",
    "    cache_folder=SENTENCE_TRANSFORMERS_HOME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a4631b5-b9a2-45e9-8a27-bfbfcfbabefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextLoader('data/book1-txt.txt').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba57f0e-e1eb-4729-88d9-57c259ea249f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 2320, which is longer than the specified 1000\n",
      "Created a chunk of size 1424, which is longer than the specified 1000\n",
      "Created a chunk of size 1001, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(separator=\".\", chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7411d1bd-604d-40d3-a66c-4ae30f019750",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What had Gulliver found on Liliput island?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3470a01-2afc-4e09-a32f-10be92e26b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(question)\n",
    "page_contents = [doc.page_content for doc in docs]\n",
    "prompt = get_question_prompt(question, page_contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b87996d8-98c9-4393-8e1c-150bb78be412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 260, which is longer than the specified 256\n"
     ]
    }
   ],
   "source": [
    "text_splitter2 = CharacterTextSplitter(chunk_size=256, chunk_overlap=0, separator=\".\",)\n",
    "documents2 = text_splitter2.create_documents([page_contents[0]])\n",
    "db2 = Chroma.from_documents(documents2, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "343b646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56bf57c4-08ef-4aca-8572-8aa553733fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = db2.similarity_search(question)\n",
    "page_contents = [doc.page_content for doc in docs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fb3b08d-0961-4d47-bdea-6a5c2e5dfe2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Gulliver may\\nbe a little dissatisfied; but I was resolved to fit the work as much as\\npossible to the general capacity of readers. However, if my own\\nignorance in sea affairs shall have led me to commit some mistakes, I\\nalone am answerable for them, and if any traveller hath a curiosity to\\nsee the whole work at large, as it came from the hand of the author, I\\nwill be ready to gratify him.\\n\\nAs for any farther particulars relating to the author, the reader will\\nreceive satisfaction from the first pages of the book.\\n\\n                                        RICHARD SYMPSON.\\n\\n[Illustration]\\n\\n[Illustration]\\n\\n\\n\\n\\nTRAVELS.\\n\\nPART I.\\n\\n\\n_A VOYAGE TO LILLIPUT_.\\n\\n\\n\\n\\nCHAPTER I.\\n\\n     THE AUTHOR GIVES SOME ACCOUNT OF HIMSELF AND FAMILY: HIS FIRST\\n     INDUCEMENTS TO TRAVEL. HE IS SHIPWRECKED, AND SWIMS FOR HIS LIFE;\\n     GETS SAFE ASHORE IN THE COUNTRY OF LILLIPUT; IS MADE A PRISONER,\\n     AND CARRIED UP THE COUNTRY.\\n\\n\\nMy father had a small estate in Nottinghamshire; I was the third of five\\nsons'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59d66744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class SummaryAnswerFormat(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "def get_question_prompt(question, context):\n",
    "    system_prompt = \"Please ensure that your responses only use the provided CONTEXT.\"\n",
    "    message = f\"Given the following CONTEXT: {context} \\nAnswer the QUESTION: {question}\"\n",
    "    prompt_template = f'<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{message} [/INST]'\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efb5d0aa-a08d-401c-a273-a639e0758372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'<s>[INST] <<SYS>>\\nPlease ensure that your responses only use the provided CONTEXT.\\n<</SYS>>\\n\\nGiven the following CONTEXT: Gulliver maybe a little dissatisfied; but I was resolved to fit the work as much aspossible to the general capacity of readers. However, if my ownignorance in sea affairs shall have led me to commit some mistakes, Ialone am answerable for them, and if any traveller hath a curiosity tosee the whole work at large, as it came from the hand of the author, Iwill be ready to gratify him.As for any farther particulars relating to the author, the reader willreceive satisfaction from the first pages of the book.RICHARD SYMPSON.[Illustration][Illustration]TRAVELS.PART I._A VOYAGE TO LILLIPUT_.CHAPTER I. THE AUTHOR GIVES SOME ACCOUNT OF HIMSELF AND FAMILY: HIS FIRST INDUCEMENTS TO TRAVEL. HE IS SHIPWRECKED, AND SWIMS FOR HIS LIFE; GETS SAFE ASHORE IN THE COUNTRY OF LILLIPUT; IS MADE A PRISONER, AND CARRIED UP THE COUNTRY.My father had a small estate in Nottinghamshire; I was the third of fivesons \\nAnswer the QUESTION: What had Gulliver found on Liliput island? [/INST]'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = get_question_prompt(question, page_contents[0].replace('\\n', '').replace('  ', ''))\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f22dca33-d229-4f3e-9e5b-416ff7af52b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from models/llama-2-13b-chat.Q2_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q2_K:   81 tensors\n",
      "llama_model_loader: - type q3_K:  200 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q2_K - Medium\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 5.06 GiB (3.34 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  5177.12 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1024\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   800.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  800.00 MiB, K (f16):  400.00 MiB, V (f16):  400.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    13.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   120.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '40', 'llama.context_length': '4096', 'llama.attention.head_count': '40', 'llama.rope.dimension_count': '128', 'general.file_type': '10', 'llama.feed_forward_length': '13824', 'llama.embedding_length': '5120', 'llama.block_count': '40', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'LLaMA v2'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# from book_worm import BookWorm\n",
    "#\n",
    "# book_worm = BookWorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea7815-79d8-456c-994a-7c9210f02e03",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "from lmformatenforcer import CharacterLevelParser, JsonSchemaParser\n",
    "\n",
    "result = book_worm._llamacpp_with_character_level_parser(prompt, JsonSchemaParser(SummaryAnswerFormat.schema()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53cf0b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "195943c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Gulliver may\\nbe a little dissatisfied; but I was resolved to fit the work as much as\\npossible to the general capacity of readers. However, if my own\\nignorance in sea affairs shall have led me to commit some mistakes, I\\nalone am answerable for them, and if any traveller hath a curiosity to\\nsee the whole work at large, as it came from the hand of the author, I\\nwill be ready to gratify him.\\n\\nAs for any farther particulars relating to the author, the reader will\\nreceive satisfaction from the first pages of the book.\\n\\n                                        RICHARD SYMPSON.\\n\\n[Illustration]\\n\\n[Illustration]\\n\\n\\n\\n\\nTRAVELS.\\n\\nPART I.\\n\\n\\n_A VOYAGE TO LILLIPUT_.\\n\\n\\n\\n\\nCHAPTER I.\\n\\n     THE AUTHOR GIVES SOME ACCOUNT OF HIMSELF AND FAMILY: HIS FIRST\\n     INDUCEMENTS TO TRAVEL. HE IS SHIPWRECKED, AND SWIMS FOR HIS LIFE;\\n     GETS SAFE ASHORE IN THE COUNTRY OF LILLIPUT; IS MADE A PRISONER,\\n     AND CARRIED UP THE COUNTRY.\\n\\n\\nMy father had a small estate in Nottinghamshire; I was the third of five\\nsons'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe6b7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace /n with nothing before creating the prompt\n",
    "# make the second similarity search based on all the responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
